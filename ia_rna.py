# -*- coding: utf-8 -*-
"""ia-rna

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aewk_rykuAT3soFWURimlBChxV-n2T8K
"""

!mkdir ia-rna

#!wget -c "https://raw.githubusercontent.com/RebeccaMartinho/dataset/main/heart_statlog.csv?token=AJQ425BDIBUBCGUAQNYE2CTA2HFPE"

!mv heart_statlog.csv /content/ia-rna

import numpy as np
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn import svm, metrics
import keras as keras

#https://www.kaggle.com/sid321axn/heart-statlog-cleveland-hungary-final?select=heart_statlog_cleveland_hungary_final.csv
# load data - previsão de doenças cardíacas
datasett = loadtxt('/content/ia-rna/heart_statlog.csv', delimiter=',')

#example of a normalization
from numpy import asarray
from sklearn.preprocessing import MinMaxScaler
data = datasett
scaler = MinMaxScaler()
dataset = scaler.fit_transform(data)

X = dataset[:,0:11] #dados
y = dataset[:,11] #classes

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)

# define model
model = Sequential()
#input_dim = dimensão de entrada, quantos atributos existem na base de dados sem o vetor classe
model.add(Dense(100, input_dim=X.shape[1], activation='relu'))#primeira camada
model.add(keras.layers.Dropout(0.2))
model.add(Dense(33, activation='relu'))#segunda camada
model.add(keras.layers.Dropout(0.2))
model.add(Dense(11, activation='relu'))#3 camada
model.add(keras.layers.Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))#camada de saida

# compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adagrad(learning_rate=0.001,
#     initial_accumulator_value=0.1,
#     epsilon=1e-07,
#     name="Adagrad",
# ), metrics=['accuracy'])
    
# model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(
#     learning_rate=0.009,
#     rho=0.9,
#     momentum=0.0,
#     epsilon=1e-07,
#     centered=False,
#     name="RMSprop",
# ),  metrics=['accuracy'])

# fit model //treinamento

#batch_size - quantidade de amostras passadas pela rede neural a cada treinamento
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=100)
print(history.history.keys())

#Gráfico do desempenho da accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

#Gráfico do desempenho do loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

# evaluate model
_, accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy*100))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

pred = model.predict_classes(X_test)
cm = confusion_matrix(y_test, pred)
print(cm)

tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()
tpr = tp/(tp+fn) #true positive
tnr = tn/(tn+fp) #true neg
acc = (tp+tn) / (tp+tn+fn+fp)
print("TPR : ", tpr)
print("TNR : ", tnr)
print("ACC: ", acc)

#AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, pred, pos_label=1)
auc = metrics.auc(fpr, tpr)
print("AUC:", auc)

#grafico curva roc
plt.plot([0,1], [0,1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)
plt.plot(fpr, tpr, color='b', label=r'ROC (AUC = %0.02F)' % (auc), lw=2, alpha=.8)
plt.suptitle('ROC CURVE')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.legend(loc='lower right')
plt.show()

#matriz de confusão 
cmx = confusion_matrix(y_test, pred)
cmd = ConfusionMatrixDisplay(cmx, display_labels=['sem doença cardíaca','com doença cardíaca'])
cmd.plot(values_format='d')

print(dataset)